# ğŸ¯ domain-chatbot
Retrieval-augmented chatbot optimized for structured and contextual domain understanding.

## ğŸ’¡ How It Works
The chatbot follows a standard Retrieval-Augmented Generation (RAG) pipeline:
1. **Document Loading** â€“ reads and parses course catalog files.  
2. **Chunking** â€“ splits text into overlapping segments for better search.  
3. **Vector Storage** â€“ embeds and stores chunks in a ChromaDB collection.  
4. **Query Processing** â€“ encodes user queries and searches for the most relevant chunks.  
5. **Response Generation** â€“ builds a contextual prompt and sends it to an LLM for the final answer.



## ğŸš€ Features
  â€¢ **Accurate course answers** â€“ delivers precise responses using your uploaded catalogs.
  
  â€¢ **RAG-powered retrieval** â€“ ensures grounded and reliable information.
  
  â€¢ **Contextual memory** â€“ keeps track of previous questions for natural conversation flow.
  
  â€¢ **Flexible model support** â€“ works seamlessly with local or remote LLMs.
  
  â€¢ **Minimal Gradio interface** â€“ fast, lightweight, and easy to use.
  

## ğŸ’» Run the Project
**1ï¸âƒ£ Activate virtual environment**
```bash
source venv/bin/activate

# for Windows:
.\venv\Scripts\activate
```
**2ï¸âƒ£ Launch the chatbot**
```bash
python chatbot.py

# Or, if youâ€™re using the Gradio interface:
python gradio_app.py  
```

**3ï¸âƒ£ ğŸ–¥ï¸ Launch desktop app (Tauri)**
```bash
cargo tauri dev  
```
## ğŸ§  Tech Stack

â€¢  **Python 3.10+** â€“ core logic and RAG pipeline

â€¢  **LangChain** â€“ retrieval, chaining, and LLM integration

â€¢  **ChromaDB** â€“ vector database for document storage and search

â€¢  **Gradio** â€“ web-based chat interface

â€¢  **Tauri + Rust** â€“ desktop app wrapper

â€¢  **Ollama / OpenRouter** â€“ local LLM backend for generating responses

â€¢  **SpaCy / Sentence Transformers** â€“ for text embedding and chunking

## ğŸ§© To Be Improved

â€¢ **Structured data parsing** â€“ fix issues with reading and understanding tables or mixed-format PDFs.

â€¢ **Chunking optimization** â€“ improve how long and structured texts are split for better retrieval.

â€¢ **Prompt flexibility** â€“ make the model handle more general or creative questions smoothly.

â€¢ **Document upload tool** â€“ add a built-in option in the UI to upload and process new files easily.
